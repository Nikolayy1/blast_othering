{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a952e966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hofin\\anaconda3\\envs\\bachelor_thesis\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerDecoderModel requires ML dependencies. Run 'pip install convokit[llm]' to install them.\n",
      "UnslothUtteranceSimulatorModel requires ML dependencies. Run 'pip install convokit[llm]' to install them.\n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "import re\n",
    "from convokit import Corpus, download\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# Method definitions\n",
    "def load_dataset_dynamic(corpus, start_index, end_index):\n",
    "    return Corpus(\n",
    "        filename=download(corpus),\n",
    "        backend=\"mem\",\n",
    "        utterance_start_index=start_index,\n",
    "        utterance_end_index=end_index,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_dataset_to_memory(corpus_path):\n",
    "    return Corpus(filename=corpus_path, backend=\"mem\")\n",
    "\n",
    "\n",
    "def get_target_ids(corpus):\n",
    "    target_ids = []\n",
    "\n",
    "    othering_terms = [\n",
    "        # Dehumanizing terms (animals, pests, disease metaphors)\n",
    "        \"animal\",\n",
    "        \"beast\",\n",
    "        \"savage\",\n",
    "        \"barbaric\",\n",
    "        \"subhuman\",\n",
    "        \"primitive\",\n",
    "        \"parasite\",\n",
    "        \"vermin\",\n",
    "        \"rat\",\n",
    "        \"cockroach\",\n",
    "        \"monster\",\n",
    "        \"brute\",\n",
    "        \"ape\",\n",
    "        \"gorilla\",\n",
    "        \"monkey\",\n",
    "        \"dog\",\n",
    "        \"pig\",\n",
    "        \"swine\",\n",
    "        \"goat\",\n",
    "        \"bug\",\n",
    "        \"leech\",\n",
    "        \"tick\",\n",
    "        \"lice\",\n",
    "        \"maggot\",\n",
    "        \"worm\",\n",
    "        \"cancer\",\n",
    "        \"tumor\",\n",
    "        \"virus\",\n",
    "        \"plague\",\n",
    "        \"infection\",\n",
    "        \"disease\",\n",
    "        # Moral judgment / worthlessness\n",
    "        \"scum\",\n",
    "        \"trash\",\n",
    "        \"filth\",\n",
    "        \"worthless\",\n",
    "        \"inferior\",\n",
    "        \"degenerate\",\n",
    "        \"lowlife\",\n",
    "        \"unworthy\",\n",
    "        \"unclean\",\n",
    "        \"impure\",\n",
    "        \"corrupt\",\n",
    "        \"dirty\",\n",
    "        \"disgusting\",\n",
    "        \"vile\",\n",
    "        \"evil\",\n",
    "        \"wicked\",\n",
    "        \"sinful\",\n",
    "        \"cursed\",\n",
    "        \"burden\",\n",
    "        \"freeloader\",\n",
    "        \"sponger\",\n",
    "        # Threatening / dangerous\n",
    "        \"dangerous\",\n",
    "        \"violent\",\n",
    "        \"aggressive\",\n",
    "        \"hostile\",\n",
    "        \"criminal\",\n",
    "        \"thug\",\n",
    "        \"deviant\",\n",
    "        \"radical\",\n",
    "        \"extremist\",\n",
    "        \"fundamentalist\",\n",
    "        \"terrorist\",\n",
    "        \"predator\",\n",
    "        \"rapist\",\n",
    "        \"gangster\",\n",
    "        \"invader\",\n",
    "        \"occupier\",\n",
    "        \"conqueror\",\n",
    "        \"infiltrator\",\n",
    "        \"threat\",\n",
    "        # Exclusion / separation\n",
    "        \"outsider\",\n",
    "        \"intruder\",\n",
    "        \"alien\",\n",
    "        \"stranger\",\n",
    "        \"foreigner\",\n",
    "        \"enemy\",\n",
    "        \"unwelcome\",\n",
    "        \"illegal\",\n",
    "        \"unwanted\",\n",
    "        \"expat\",\n",
    "        \"outcast\",\n",
    "        \"undesirable\",\n",
    "        \"colonizer\",\n",
    "        \"settler\",\n",
    "        # Diminishing / infantilizing\n",
    "        \"ignorant\",\n",
    "        \"backward\",\n",
    "        \"naive\",\n",
    "        \"uncivilized\",\n",
    "        \"helpless\",\n",
    "        \"weak\",\n",
    "        \"stupid\",\n",
    "        \"lazy\",\n",
    "        \"immature\",\n",
    "        \"childlike\",\n",
    "        \"silly\",\n",
    "        \"emotional\",\n",
    "        \"hysterical\",\n",
    "        \"irrational\",\n",
    "        \"clueless\",\n",
    "        \"brainwashed\",\n",
    "        \"sheep\",\n",
    "        \"puppet\",\n",
    "        \"follower\",\n",
    "        # Religion & secular identities\n",
    "        \"atheists\",\n",
    "        \"non-believers\",\n",
    "        \"secular people\",\n",
    "        \"buddhists\",\n",
    "        \"buddhist people\",\n",
    "        \"hindus\",\n",
    "        \"hindu people\",\n",
    "        \"christians\",\n",
    "        \"christian people\",\n",
    "        \"catholics\",\n",
    "        \"protestants\",\n",
    "        \"mormons\",\n",
    "        \"evangelicals\",\n",
    "        \"pagans\",\n",
    "        \"satanists\",\n",
    "        \"muslims\",\n",
    "        \"islamic people\",\n",
    "        \"islamists\",\n",
    "        \"muzzies\",\n",
    "        \"ragheads\",\n",
    "        \"jews\",\n",
    "        \"jewish people\",\n",
    "        \"zionists\",\n",
    "        \"orthodox jews\",\n",
    "        # Migration / nationality\n",
    "        \"immigrants\",\n",
    "        \"migrants\",\n",
    "        \"foreigners\",\n",
    "        \"outsiders\",\n",
    "        \"refugees\",\n",
    "        \"asylum seekers\",\n",
    "        \"expats\",\n",
    "        \"nationals\",\n",
    "        \"illegal aliens\",\n",
    "        \"illegals\",\n",
    "        \"invaders\",\n",
    "        \"colonizers\",\n",
    "        \"settlers\",\n",
    "        # Gender & women\n",
    "        \"women\",\n",
    "        \"woman\",\n",
    "        \"girl\",\n",
    "        \"girls\",\n",
    "        \"females\",\n",
    "        \"ladies\",\n",
    "        \"wives\",\n",
    "        \"mothers\",\n",
    "        \"bitches\",\n",
    "        \"sluts\",\n",
    "        \"whores\",\n",
    "        \"feminists\",\n",
    "        \"feminazis\",\n",
    "        # LGBTQ+\n",
    "        \"lgbtq\",\n",
    "        \"gay\",\n",
    "        \"gays\",\n",
    "        \"lesbian\",\n",
    "        \"lesbians\",\n",
    "        \"bisexual\",\n",
    "        \"transgender\",\n",
    "        \"trans\",\n",
    "        \"tranny\",\n",
    "        \"trannies\",\n",
    "        \"queer\",\n",
    "        \"queers\",\n",
    "        \"dyke\",\n",
    "        \"dykes\",\n",
    "        \"faggot\",\n",
    "        \"faggots\",\n",
    "        \"non-binary\",\n",
    "        \"drag queens\",\n",
    "        \"drag kings\",\n",
    "    ]\n",
    "\n",
    "    # Pre-compile regex patterns\n",
    "    patterns = [\n",
    "        re.compile(r\"(?i)(?<!\\w)\" + re.escape(term) + r\"(?!\\w)\")\n",
    "        for term in othering_terms\n",
    "    ]\n",
    "\n",
    "    for utt in corpus.iter_utterances():\n",
    "        if not utt.text:  # skip empty text\n",
    "            continue\n",
    "\n",
    "        # Count words\n",
    "        word_count = len(utt.text.split())\n",
    "\n",
    "        if word_count < 100 and any(p.search(utt.text) for p in patterns):\n",
    "            target_ids.append(utt.id)\n",
    "\n",
    "    return target_ids\n",
    "\n",
    "\n",
    "def get_id_chain(corpus, target_id):\n",
    "    chain = []\n",
    "    utt = corpus.get_utterance(target_id)\n",
    "    while utt is not None:\n",
    "        chain.append(utt)\n",
    "        utt = corpus.get_utterance(utt.reply_to) if utt.reply_to else None\n",
    "\n",
    "    # reverse so it's from root → target\n",
    "    chain = chain[::-1]\n",
    "    return chain\n",
    "\n",
    "\n",
    "def plot_wordcloud(chain, title):\n",
    "    all_words = \" \".join(u.text for u in chain).lower()\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, height=400, background_color=\"white\", stopwords=STOPWORDS\n",
    "    ).generate(all_words)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def export_comments_to_json(corpus, target_ids, filepath):\n",
    "    \"\"\"\n",
    "    Export selected comments into JSON format:\n",
    "    one big JSON object with numeric keys.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for idx, target_id in enumerate(target_ids, start=1):\n",
    "        utt = corpus.get_utterance(target_id)\n",
    "        if utt is None:\n",
    "            continue\n",
    "\n",
    "        # build id chain\n",
    "        id_chain = []\n",
    "        for i in get_id_chain(corpus, target_id):\n",
    "            id_chain.append({\"id\": i.id})\n",
    "\n",
    "        # get up to 3 preceding comments\n",
    "        last_idx = len(id_chain) - 1\n",
    "        start = max(0, last_idx - 3)\n",
    "        end = last_idx\n",
    "        context_ids = id_chain[start:end]\n",
    "\n",
    "        # collect context text\n",
    "        context_text = []\n",
    "        for entry in context_ids:\n",
    "            ctx_utt = corpus.get_utterance(entry[\"id\"])\n",
    "            if ctx_utt and ctx_utt.text:\n",
    "                context_text.append(ctx_utt.text)\n",
    "\n",
    "        # extract top keywords from context\n",
    "        context = categorize_chunks(\" \".join(context_text), top_n=10)\n",
    "\n",
    "        # build record\n",
    "        record = {\n",
    "            \"id\": target_id,\n",
    "            \"text\": getattr(utt, \"text\", None),\n",
    "            \"timestamp\": getattr(utt, \"timestamp\", None),\n",
    "            \"conversation_id\": getattr(utt, \"conversation_id\", None),\n",
    "            \"comment_chain\": id_chain,\n",
    "            \"context\": context,\n",
    "        }\n",
    "        results[idx] = record  # numeric keys\n",
    "\n",
    "    # save to JSON\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Saved {len(results)} comments to {filepath} (JSON format)\")\n",
    "\n",
    "\n",
    "\n",
    "def export_comments_to_jsonl(corpus, target_ids, filepath):\n",
    "    \"\"\"\n",
    "    Export selected comments into JSONL format:\n",
    "    one JSON object per line.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for target_id in target_ids:\n",
    "            utt = corpus.get_utterance(target_id)\n",
    "            if utt is None:\n",
    "                continue\n",
    "            \n",
    "            id_chain = []\n",
    "            context = []\n",
    "    \n",
    "            for i in get_id_chain(corpus, target_id):\n",
    "                id_chain.append({\"id\": i.id})\n",
    "    \n",
    "            last_idx = len(id_chain) - 1\n",
    "            start = max(0, last_idx - 3)  # up to 3 preceding comments\n",
    "            end = last_idx\n",
    "            context_ids = id_chain[start:end]\n",
    "\n",
    "            context_text = []\n",
    "            for id in context_ids:\n",
    "                context_text.append(corpus.get_utterance(id[\"id\"]).text)\n",
    "\n",
    "            context = categorize_chunks(\" \".join(context_text), top_n=10)\n",
    "\n",
    "            record = {\n",
    "            \"id\": target_id,\n",
    "            \"text\": getattr(utt, \"text\", None),\n",
    "            \"timestamp\": getattr(utt, \"timestamp\", None),\n",
    "            \"conversation_id\": getattr(utt, \"conversation_id\", None),\n",
    "            \"comment_chain\": id_chain,\n",
    "            \"context\": context,\n",
    "            }\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "            count += 1\n",
    "\n",
    "    print(f\"✅ Saved {count} comments to {filepath} (JSONL format)\")\n",
    "    \n",
    "def categorize_chunks(text, top_n=10):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # collect candidate words/phrases\n",
    "    candidates = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        phrase = chunk.text.lower().strip()\n",
    "        if not all(token.is_stop for token in chunk):  # skip only-stopword chunks\n",
    "            candidates.append(phrase)\n",
    "\n",
    "    # deduplicate while preserving order\n",
    "    seen, keywords = set(), []\n",
    "    for c in candidates:\n",
    "        if c not in seen:\n",
    "            seen.add(c)\n",
    "            keywords.append(c)\n",
    "\n",
    "    return keywords[:top_n]\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    # Collapse multiple newlines into one space\n",
    "    text = re.sub(r\"\\s*\\n\\s*\", \" \", text)\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def clean_links(text: str, keep_anchor=True):\n",
    "    # Remove markdown-style links [text](url)\n",
    "    if keep_anchor:\n",
    "        return re.sub(r\"\\[([^\\]]+)\\]\\([^)]+\\)\", r\"\\1\", text)\n",
    "    else:\n",
    "        return re.sub(r\"\\[([^\\]]+)\\]\\([^)]+\\)\", \"[URL]\", text)\n",
    "    \n",
    "def clean_html_tags(text: str) -> str:\n",
    "   return html.unescape(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6bff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at C:\\Users\\hofin\\.convokit\\saved-corpora\\reddit-corpus-small\n"
     ]
    }
   ],
   "source": [
    "corpus = load_dataset_dynamic(\"reddit-corpus-small\", 0, 10000)\n",
    "target_ids = get_target_ids(corpus)\n",
    "\n",
    "# for target_id in target_ids:\n",
    "#     chain = get_id_chain(corpus, target_id)\n",
    "#     for u in chain:\n",
    "#         print(f\"{u.id}\")\n",
    "#     print(\"-----\")\n",
    "\n",
    "# print(target_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f50cad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 17532 comments to data_collection/reddit-corpus-small.json (JSON format)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#target_ids = get_target_ids(corpus)\n",
    "\n",
    "os.chdir(r\"C:\\Users\\hofin\\OneDrive - Fachhochschule St. Pölten\\__BachelorThesis\\blast_othering\")\n",
    "\n",
    "\n",
    "export_comments_to_json(corpus, target_ids, \"data_collection/reddit-corpus-small.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f220876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved first 100\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\hofin\\OneDrive - Fachhochschule St. Pölten\\__BachelorThesis\\blast_othering\")\n",
    "\n",
    "with open(\"data_collection/reddit-corpus-small.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "# keep only the first `limit` items\n",
    "sliced = {k: data[k] for k in list(data.keys())[:100]}\n",
    "\n",
    "with open(\"data_collection/reddit-corpus-small-100.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sliced, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Saved first {len(sliced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a0213da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_collection/reddit-corpus-small-100.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for key in data:\n",
    "    data[key][\"text\"] = clean_text(data[key][\"text\"])\n",
    "    data[key][\"text\"] = clean_links(data[key][\"text\"])\n",
    "    data[key][\"text\"] = clean_html_tags(data[key][\"text\"])\n",
    "    \n",
    "with open(\"data_collection/reddit-corpus-small-100.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f80982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved JSON to reddit_corpus.xlsx\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_collection/reddit-corpus-small-100.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# Convert dict-of-dicts into a list of records\n",
    "records = []\n",
    "for key, value in data.items():\n",
    "    record = {\"id\": key}\n",
    "    record.update(value)\n",
    "    records.append(record)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel(\"reddit_corpus.xlsx\", index=False)\n",
    "print(\"✅ Saved JSON to reddit_corpus.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7ecfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1\n",
      "Text: Gotta look out for those foreign immigrants.\n",
      "Reason: The comment implies that 'foreign immigrants' are a group that needs to be looked out for, suggesting they might be a threat or a problem, thus positioning them as inferior or outside the norm.\n",
      "-----\n",
      "ID: 4\n",
      "Text: Instead they get ass raped by somalian and other mudslime immigrants.\n",
      "Reason: The comment contains a clear us-vs-them contrast and positions the mentioned group as inferior, with dehumanizing language.\n",
      "-----\n",
      "ID: 3\n",
      "Text: yet another example of aggressive militant feminism hurting women more than it helps them.\n",
      "Reason: The comment creates an us-vs-them contrast by portraying 'aggressive militant feminism' as a harmful and opposing force to the well-being of women, implying that this group is acting against the interests of women.\n",
      "-----\n",
      "ID: 2\n",
      "Text: christ, women are fucking stupid\n",
      "Reason: The comment expresses a strong negative sentiment towards women, framing them as inferior and excluded.\n",
      "-----\n",
      "ID: 5\n",
      "Text: Why are women so lazy?\n",
      "Reason: The comment implies that women are inherently lazy, which is a negative stereotype that can be perceived as inferiorizing or excluding them.\n",
      "-----\n",
      "ID: 6\n",
      "Text: It is still OK to make fun of other species tho, like Jews\n",
      "Reason: The comment makes a joke at the expense of a specific ethnic group, implying that it's acceptable to mock them.\n",
      "-----\n",
      "ID: 7\n",
      "Text: you mean, no reason to hate jews more than any other religion.\n",
      "Reason: The comment implies that Jews are a group that can be hated, which positions them as inferior or excluded.\n",
      "-----\n",
      "ID: 8\n",
      "Text: sandniggers are just as beautiful as any other women\n",
      "Reason: The term 'sandniggers' is a racial slur and derogatory term, implying that the group being referred to is inferior or outside the norm.\n",
      "-----\n",
      "ID: 9\n",
      "Text: Fuck women and their socialistic scumshitlord ways of objectifying men.\n",
      "Reason: The comment expresses a strong negative sentiment towards women, positioning them as inferior and excluded.\n",
      "-----\n",
      "ID: 10\n",
      "Text: degenerate atheists\n",
      "Reason: The comment uses a derogatory term to describe a group of people, implying they are inferior or morally corrupt.\n",
      "-----\n",
      "ID: 12\n",
      "Text: It applies to both women and girls, and they're both astoundingly weak\n",
      "Reason: The comment explicitly states that a group is 'astoundingly weak', which positions them as inferior.\n",
      "-----\n",
      "ID: 14\n",
      "Text: Anyway tatar are non-white scum like niggers, jews and Turks.\n",
      "Reason: The comment contains a clear us-vs-them contrast by using derogatory language to refer to multiple ethnic groups, positioning them as inferior.\n",
      "-----\n",
      "ID: 15\n",
      "Text: That guy's just retarded.\n",
      "Reason: The comment uses a derogatory term to describe someone, implying inferiority or exclusion.\n",
      "-----\n",
      "ID: 16\n",
      "Text: And feeling like some behind-enemy-lines spy going into the lesbian chat room!\n",
      "Reason: The comment positions lesbians as 'other' by using a military metaphor that implies infiltration or spying, suggesting an us-vs-them contrast and exclusion.\n",
      "-----\n",
      "ID: 18\n",
      "Text: You are a really retarded piece of shit.\n",
      "Reason: The comment contains derogatory language targeting an individual or group, implying inferiority and exclusion.\n",
      "-----\n",
      "ID: 19\n",
      "Text: It's stupid, but it works with some women.\n",
      "Reason: The statement implies that a particular approach is effective only with certain women, framing them as a group that can be manipulated or taken advantage of, which positions them as inferior or 'other'.\n",
      "-----\n",
      "ID: 22\n",
      "Text: Stupid and gay, not a lot going for you in this life.\n",
      "Reason: The comment contains derogatory language targeting an individual based on their sexual orientation and perceived intelligence or worth, creating an us-vs-them contrast.\n",
      "-----\n",
      "ID: 23\n",
      "Text: I mean, all women are stupid, so that shouldn't surprise you\n",
      "Reason: The comment clearly expresses a negative and discriminatory view of women, framing them as inferior and excluded.\n",
      "-----\n",
      "ID: 24\n",
      "Text: Women don't like to work.\n",
      "Reason: The statement makes a generalization about women based on gender, implying they are less willing to work, which can be seen as positioning them as inferior or less capable.\n",
      "-----\n",
      "ID: 25\n",
      "Text: make it illegal for Jews to hold jobs/own land.\n",
      "Reason: The comment explicitly targets and excludes a specific social group, Jews, from participating in the economy and owning property, which is a clear indication of inferiority and exclusion.\n",
      "-----\n",
      "ID: 27\n",
      "Text: If their entire religious following was removed from this planet, we wouldnt lose a single thing except a threat to civilized culture.\n",
      "Reason: The comment frames the mentioned group as a threat to civilized culture and implies that their removal would not be a loss, which positions them as inferior and outside belonging.\n",
      "-----\n",
      "ID: 28\n",
      "Text: Blacks are more likely to commit violent crime over East Asians, mostly due to biological differences\n",
      "Reason: The comment implies that one racial group is inherently more prone to violence than another due to biological differences, which positions the mentioned groups as inferior and excluded.\n",
      "-----\n",
      "ID: 29\n",
      "Text: Men are more likely to commit violent crime over women, mostly due to biological differences\n",
      "Reason: The comment implies that men are inherently more prone to violence than women due to biological differences, positioning men as a group with a higher likelihood of committing violent crimes. This framing can be seen as 'othering' because it creates an us-vs-them contrast between men and women, with men being portrayed as more aggressive or violent.\n",
      "-----\n",
      "ID: 30\n",
      "Text: Cracks me up that women think they're as degenerate as men\n",
      "Reason: The comment implies that women are trying to be as 'degenerate' as men, which positions them as inferior and outside the norm of expected behavior.\n",
      "-----\n",
      "ID: 31\n",
      "Text: Women. Are. Shit. At. Driving.\n",
      "Reason: The comment clearly expresses a derogatory and discriminatory view towards women, framing them as inferior in driving abilities.\n",
      "-----\n",
      "ID: 32\n",
      "Text: But on the other hand his girls a stupid slut and needs to be set on fire and drowned in sewage.\n",
      "Reason: The target group 'his girl' is positioned as inferior, with extremely derogatory language used to describe them.\n",
      "-----\n",
      "ID: 33\n",
      "Text: Cuz Jews print the news, fuck the other 6 million that died who were not Jews.\n",
      "Reason: The comment contains a clear us-vs-them contrast by mentioning 'the other' in relation to Jewish people and implying inferiority or exclusion of non-Jewish people who died, which is evidence of othering.\n",
      "-----\n",
      "ID: 37\n",
      "Text: Americans have been far too lenient with the protestants and their backward ways.\n",
      "Reason: The comment positions Protestants as an outgroup by describing them as having 'backward ways', implying they are inferior or less advanced than others, specifically Americans.\n",
      "-----\n",
      "ID: 38\n",
      "Text: Society places a far higher value on the life of a woman than that of a man.\n",
      "Reason: The comment implies that society values women's lives more than men's, positioning men as inferior or less valued.\n",
      "-----\n",
      "ID: 39\n",
      "Text: atheists spend more time antagonizing Christians than any other religious groups\n",
      "Reason: The comment implies that atheists are overly critical and hostile towards Christians, creating an us-vs-them contrast and positioning atheists as inferior or outside the norm.\n",
      "-----\n",
      "ID: 40\n",
      "Text: Men harm society more than women.\n",
      "Reason: The statement implies that men are more harmful to society than women, which positions men as inferior and excluded from the rest of society.\n",
      "-----\n",
      "ID: 41\n",
      "Text: In today's world, the overall net effect would be positive if Islamic doctrine disappeared.\n",
      "Reason: The comment implies that the disappearance of Islamic doctrine would have a positive effect, positioning Islam as inferior or problematic.\n",
      "-----\n",
      "ID: 42\n",
      "Text: The Middle East would be more stable if it underwent de-Arabization and border changes\n",
      "Reason: The comment suggests that the Middle East would be more stable if it underwent significant changes, including de-Arabization, which implies that Arab identity or presence is a problem to be solved. This framing positions Arabs as 'other' and inferior, implying that their existence or cultural identity is a barrier to stability in the region.\n",
      "-----\n",
      "ID: 43\n",
      "Text: Wait, Muslims actually fucking accomplished something other than violence?\n",
      "Reason: The comment frames Muslims as 'other' and positions them as inferior by expressing surprise that they have accomplished something positive, implying that their typical behavior is violent.\n",
      "-----\n",
      "ID: 44\n",
      "Text: I hope you get axe murdered for Christmas you wothless fucking cocksucker.\n",
      "Reason: The comment contains a clear us-vs-them contrast, with the target group being positioned as inferior and excluded, using derogatory language.\n",
      "-----\n",
      "ID: 45\n",
      "Text: Poor, dirty foreigner...\n",
      "Reason: The comment contains a derogatory term for foreigners, implying they are poor and dirty, which positions them as inferior and outside belonging.\n",
      "-----\n",
      "ID: 46\n",
      "Text: You sound like those Middle East apologists who think treating women as property is a valid cultural difference.\n",
      "Reason: The comment implies that people from the Middle East or those who apologize for its culture are inferior and outside of what is considered acceptable, framing them as 'other'. The mention of 'treating women as property' creates an us-vs-them contrast by implying that this behavior is specific to the mentioned group and is not a valid cultural difference.\n",
      "-----\n",
      "ID: 47\n",
      "Text: Fuck youre so stupid, I thought you jews had high verbal iq\n",
      "Reason: The comment contains a derogatory slur and stereotype targeting a specific ethnic/religious group, implying their inferiority.\n",
      "-----\n",
      "ID: 48\n",
      "Text: Democrats speak about white people the way Hitler spoke of the jews.\n",
      "Reason: The comment compares Democrats' speech about white people to Hitler's speech about Jews, implying an us-vs-them contrast and positioning white people as inferior or excluded.\n",
      "-----\n",
      "ID: 51\n",
      "Text: She sounds like inconsiderate trash\n",
      "Reason: The comment uses derogatory language to describe someone, positioning them as inferior and outside belonging.\n",
      "-----\n",
      "ID: 54\n",
      "Text: It should be illegal *nationwide* to pay housing rent to foreigners.\n",
      "Reason: The comment suggests that it should be illegal for foreigners to receive housing rent, which positions them as inferior or outside the norm, creating an us-vs-them contrast.\n",
      "-----\n",
      "ID: 55\n",
      "Text: I will never support illegal immigrants holding public office.\n",
      "Reason: The comment implies that 'illegal immigrants' are inherently unqualified or unfit for public office, which positions them as inferior and excluded from belonging.\n",
      "-----\n",
      "ID: 58\n",
      "Text: that is a disgusting piece of slime that should never have been allowed to become POTUS\n",
      "Reason: The comment expresses strong negative feelings towards the current President of the United States, using dehumanizing language and implying they are unfit for office.\n",
      "-----\n",
      "ID: 59\n",
      "Text: At the very least the guy is a loser, criminal and idiot.\n",
      "Reason: The comment contains strong negative language directed at an individual, framing them as inferior and outside belonging due to their actions and perceived character.\n",
      "-----\n",
      "ID: 61\n",
      "Text: You'll suspect someone from Bangladesh of terrorism before someone from Turkey.\n",
      "Reason: The comment implies a suspicion of terrorism based on nationality, creating an us-vs-them contrast and positioning people from Bangladesh as potentially inferior or dangerous.\n",
      "-----\n",
      "ID: 62\n",
      "Text: Most men are pigs and rapists\n",
      "Reason: The comment makes a sweeping generalization about men, framing them as inherently bad and criminal, which can be seen as 'othering' by creating an us-vs-them contrast.\n",
      "-----\n",
      "ID: 63\n",
      "Text: If women's tennis is known as the \"sport where chicks freak out at the refs\" then it's her fault.\n",
      "Reason: The text contains a derogatory statement about women's tennis, framing female players in a negative and stereotypical way.\n",
      "-----\n",
      "ID: 65\n",
      "Text: Fuck you and your normalization of hating Jews\n",
      "Reason: The comment contains a direct attack on a specific group (Jews) and uses derogatory language, implying inferiority or exclusion.\n",
      "-----\n",
      "ID: 66\n",
      "Text: Turns out women are weak huh.\n",
      "Reason: The comment implies that women are inherently inferior to men due to their perceived weakness, creating an us-vs-them contrast and positioning women as outside the dominant group.\n",
      "-----\n",
      "ID: 67\n",
      "Text: most women aren't that stupid\n",
      "Reason: The comment implies that most women lack intelligence, which is a negative and exclusionary framing.\n",
      "-----\n",
      "ID: 68\n",
      "Text: This sub is just becoming a place for people to openly hate on women.\n",
      "Reason: The comment frames the mentioned group (women) as being hated on, implying inferiority or exclusion.\n",
      "-----\n",
      "ID: 69\n",
      "Text: Those people are stupid\n",
      "Reason: The comment implies that a certain group of people is inferior due to their lack of intelligence.\n",
      "-----\n",
      "ID: 70\n",
      "Text: They have chosen one side as \"the good guys\", the oppressed victims who need protection from the enemy (White Man).\n",
      "Reason: The text creates an us-vs-them contrast by portraying 'White Man' as 'the enemy', positioning this group as a threat to be protected against, thus framing it as 'other'.\n",
      "-----\n",
      "ID: 76\n",
      "Text: just like I thought ~~gay~~trash\n",
      "Reason: The comment contains a derogatory term for gay people, implying they are inferior or worthless.\n",
      "-----\n",
      "ID: 78\n",
      "Text: I'm beyond sick of Christians shoving their shit down other Americans' throats.\n",
      "Reason: The comment expresses strong negative feelings towards a specific group, framing them as imposing their beliefs on others and positioning them as an out-group.\n",
      "-----\n",
      "ID: 79\n",
      "Text: A worthless whore like that one is not worth it\n",
      "Reason: The comment contains a derogatory term for a woman and implies she is worthless, positioning her as inferior.\n",
      "-----\n",
      "ID: 82\n",
      "Text: I was trying to be politically correct, but what I was really referring to are immigrants from the Middle East and North Africa who generally practice radical islam.\n",
      "Reason: The text frames a specific group as 'other' by implying that they are more likely to practice radical Islam, which may be perceived as inferior or dangerous.\n",
      "-----\n",
      "ID: 83\n",
      "Text: a bunch of other stupid bullshit christian laws\n",
      "Reason: The comment contains derogatory language towards Christian laws, framing Christians as 'other' and positioning them in an us-vs-them contrast.\n",
      "-----\n",
      "ID: 87\n",
      "Text: Black women have the lowest value in the eyes of men of pretty much any race.\n",
      "Reason: The comment frames black women as having low value, which positions them as inferior and excluded.\n",
      "-----\n",
      "ID: 91\n",
      "Text: American women are the only stupid bitches getting pregnant at 40\n",
      "Reason: The comment contains a derogatory statement targeting a specific group, American women, implying they are inferior or stupid for getting pregnant at 40.\n",
      "-----\n",
      "ID: 92\n",
      "Text: The cancer of feminism won't be stopped until it's universally condemned.\n",
      "Reason: The comment frames feminism as a 'cancer', implying that it is harmful and should be condemned, creating an us-vs-them contrast between those who support feminism and those who do not.\n",
      "-----\n",
      "ID: 93\n",
      "Text: ~~Radical~~ muslims are the ebola of Europe.\n",
      "Reason: The comment uses a metaphor that compares radical Muslims to Ebola, framing them as a deadly and destructive force in Europe, creating an us-vs-them contrast.\n",
      "-----\n",
      "ID: 94\n",
      "Text: Meanwhile fat white girls are the ones thinking obesity is \"curvy\".\n",
      "Reason: The comment implies that a specific group, 'fat white girls', are ignorant or misguided about their body shape and health, positioning them as inferior to others.\n",
      "-----\n",
      "ID: 95\n",
      "Text: LGBTQ are scum, worse than liberals.\n",
      "Reason: The comment expresses strong negative feelings and exclusion towards the LGBTQ group, positioning them as inferior and outside belonging.\n",
      "-----\n",
      "ID: 96\n",
      "Text: All trannies are part of LGBTQ, being the T in that coagulation of filth.\n",
      "Reason: The comment contains a derogatory term and positions transgender individuals as inferior and outside belonging.\n",
      "-----\n",
      "ID: 97\n",
      "Text: Calling Muslims 'subhuman' is an insult to subhumans\n",
      "Reason: The comment positions Muslims as inferior by comparing them unfavorably to another group, implying that they are less worthy or less human.\n",
      "-----\n",
      "ID: 99\n",
      "Text: Why are women so whiny?\n",
      "Reason: The comment positions women as inferior by using a derogatory term and making a generalization about their behavior.\n",
      "-----\n",
      "Total Othering entries: 67\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\hofin\\OneDrive - Fachhochschule St. Pölten\\__BachelorThesis\\blast_othering\")\n",
    "\n",
    "with open(\"data/results/78/stage_6_results_78.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "# go into the \"data\" field of your JSON\n",
    "for key, entry in data[\"data\"].items():\n",
    "    if entry[\"annotation\"][\"label\"] == \"Othering\":\n",
    "        print(f\"ID: {key}\")\n",
    "        print(f\"Text: {entry['text']}\")\n",
    "        print(f\"Reason: {entry['annotation']['reasoning']}\")\n",
    "        print(\"-----\")\n",
    "        \n",
    "print(f\"Total Othering entries: {len([entry for entry in data['data'].values() if entry['annotation']['label'] == 'Othering'])}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e8a44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
